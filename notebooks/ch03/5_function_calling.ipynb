{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00f44e17-ed2d-47e7-887d-c07490a50f83",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üìù Colab Users - Uncomment & Run the following 2 Cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e353e1e-ace8-4ee5-9bef-86a9155e764b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install hopsworks --quiet\n",
    "#!pip install xgboost==2.0.3 --quiet\n",
    "#!pip install scikit-learn==1.4.1.post1 --quiet\n",
    "#!pip install langchain==0.1.10 --quiet\n",
    "#!pip install bitsandbytes==0.42.0 --quiet\n",
    "#!pip install accelerate==0.27.2 --quiet\n",
    "#!pip install transformers==4.38.2 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c75092c-6e9b-4bad-9ebc-b0405f914dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir -p functions\n",
    "# !cd functions && wget https://raw.githubusercontent.com/featurestorebook/mlfs-book/main/notebooks/ch03/functions/air_quality_data_retrieval.py \n",
    "# !cd functions && wget https://raw.githubusercontent.com/featurestorebook/mlfs-book/main/notebooks/ch03/functions/context_engineering.py\n",
    "# !cd functions && wget https://raw.githubusercontent.com/featurestorebook/mlfs-book/main/notebooks/ch03/functions/llm_chain.py\n",
    "# !cd functions && wget https://raw.githubusercontent.com/featurestorebook/mlfs-book/main/notebooks/ch03/functions/util.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f3f016",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üìù Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "721ae546",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/palhagen/Desktop/Proggramering/Scalable Machine Learning/mlfs-book/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'distutils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XGBRegressor\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mhopsworks\u001b[39;00m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctions\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllm_chain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      5\u001b[0m     load_model, \n\u001b[1;32m      6\u001b[0m     get_llm_chain, \n\u001b[1;32m      7\u001b[0m     generate_response, \n\u001b[1;32m      8\u001b[0m     generate_response_openai,\n\u001b[1;32m      9\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/Proggramering/Scalable Machine Learning/mlfs-book/.venv/lib/python3.12/site-packages/hopsworks/__init__.py:33\u001b[0m\n\u001b[1;32m     30\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(action\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m, category\u001b[38;5;241m=\u001b[39m\u001b[38;5;167;01mUserWarning\u001b[39;00m, module\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.*psycopg2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mhsml\u001b[39;00m  \u001b[38;5;66;03m# noqa: F401, E402\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mhsfs\u001b[39;00m  \u001b[38;5;66;03m# noqa: F401, E402\u001b[39;00m\n\u001b[1;32m     35\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m version\u001b[38;5;241m.\u001b[39m__version__\n\u001b[1;32m     37\u001b[0m connection \u001b[38;5;241m=\u001b[39m Connection\u001b[38;5;241m.\u001b[39mconnection\n",
      "File \u001b[0;32m~/Desktop/Proggramering/Scalable Machine Learning/mlfs-book/.venv/lib/python3.12/site-packages/hsfs/__init__.py:20\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhsfs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m util, version\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhsfs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconnection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Connection\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhsfs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m usage\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnest_asyncio\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Proggramering/Scalable Machine Learning/mlfs-book/.venv/lib/python3.12/site-packages/hsfs/connection.py:24\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhsfs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecorators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m connected, not_connected\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhsfs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopensearch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenSearchClientSingleton\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhsfs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m engine, client, util, usage\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhsfs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     26\u001b[0m     feature_store_api,\n\u001b[1;32m     27\u001b[0m     project_api,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m     variable_api,\n\u001b[1;32m     31\u001b[0m )\n\u001b[1;32m     33\u001b[0m AWS_DEFAULT_REGION \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/Proggramering/Scalable Machine Learning/mlfs-book/.venv/lib/python3.12/site-packages/hsfs/engine/__init__.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#   Copyright 2020 Logical Clocks AB\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#   limitations under the License.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhsfs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m spark, spark_no_metastore\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhsfs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m exceptions\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhsfs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m arrow_flight_client\n",
      "File \u001b[0;32m~/Desktop/Proggramering/Scalable Machine Learning/mlfs-book/.venv/lib/python3.12/site-packages/hsfs/engine/spark.py:77\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhsfs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m feature, training_dataset_feature, client, util\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhsfs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_group\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExternalFeatureGroup, SpineGroup\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhsfs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstorage_connector\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StorageConnector\n",
      "File \u001b[0;32m~/Desktop/Proggramering/Scalable Machine Learning/mlfs-book/.venv/lib/python3.12/site-packages/hsfs/training_dataset_feature.py:19\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#   Copyright 2020 Logical Clocks AB\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#   limitations under the License.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mhumps\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mhsfs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_group\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mfeature_group\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhsfs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Feature\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhsfs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransformation_function\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TransformationFunction\n",
      "File \u001b[0;32m~/Desktop/Proggramering/Scalable Machine Learning/mlfs-book/.venv/lib/python3.12/site-packages/hsfs/feature_group.py:21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhsfs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membedding\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EmbeddingIndex\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhsfs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mge_validation_result\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ValidationResult\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mhumps\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Proggramering/Scalable Machine Learning/mlfs-book/.venv/lib/python3.12/site-packages/hsfs/ge_validation_result.py:23\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdateutil\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mhumps\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgreat_expectations\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mge\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhsfs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m util\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mValidationResult\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/Proggramering/Scalable Machine Learning/mlfs-book/.venv/lib/python3.12/site-packages/great_expectations/__init__.py:7\u001b[0m\n\u001b[1;32m      4\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m get_versions()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mversion\u001b[39m\u001b[38;5;124m\"\u001b[39m]  \u001b[38;5;66;03m# isort:skip\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m get_versions  \u001b[38;5;66;03m# isort:skip\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_context\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataContext\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     10\u001b[0m     from_pandas,\n\u001b[1;32m     11\u001b[0m     get_context,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m     validate,\n\u001b[1;32m     21\u001b[0m )\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# from great_expectations.expectations.core import *\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# from great_expectations.expectations.metrics import *\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Proggramering/Scalable Machine Learning/mlfs-book/.venv/lib/python3.12/site-packages/great_expectations/data_context/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_context\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_context\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      2\u001b[0m     AbstractDataContext,\n\u001b[1;32m      3\u001b[0m     BaseDataContext,\n\u001b[1;32m      4\u001b[0m     CloudDataContext,\n\u001b[1;32m      5\u001b[0m     DataContext,\n\u001b[1;32m      6\u001b[0m     EphemeralDataContext,\n\u001b[1;32m      7\u001b[0m     ExplorerDataContext,\n\u001b[1;32m      8\u001b[0m     FileDataContext,\n\u001b[1;32m      9\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/Proggramering/Scalable Machine Learning/mlfs-book/.venv/lib/python3.12/site-packages/great_expectations/data_context/data_context/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_context\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_context\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mabstract_data_context\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      2\u001b[0m     AbstractDataContext,\n\u001b[1;32m      3\u001b[0m )\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_context\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_context\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase_data_context\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      5\u001b[0m     BaseDataContext,\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_context\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_context\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud_data_context\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      8\u001b[0m     CloudDataContext,\n\u001b[1;32m      9\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/Proggramering/Scalable Machine Learning/mlfs-book/.venv/lib/python3.12/site-packages/great_expectations/data_context/data_context/abstract_data_context.py:10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mabc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ABC, abstractmethod\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dict, Mapping, Optional, Union, cast\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01myaml_handler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m YAMLHandler\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_context\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_context_variables\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataContextVariables\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_context\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     13\u001b[0m     DataContextConfig,\n\u001b[1;32m     14\u001b[0m     anonymizedUsageStatisticsSchema,\n\u001b[1;32m     15\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/Proggramering/Scalable Machine Learning/mlfs-book/.venv/lib/python3.12/site-packages/great_expectations/core/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexpectation_suite\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      4\u001b[0m     ExpectationConfiguration,\n\u001b[1;32m      5\u001b[0m     ExpectationConfigurationSchema,\n\u001b[1;32m      6\u001b[0m     ExpectationSuite,\n\u001b[1;32m      7\u001b[0m     ExpectationSuiteSchema,\n\u001b[1;32m      8\u001b[0m     expectationSuiteSchema,\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexpectation_validation_result\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     11\u001b[0m     ExpectationSuiteValidationResult,\n\u001b[1;32m     12\u001b[0m     ExpectationSuiteValidationResultSchema,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m     get_metric_kwargs_id,\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mid_dict\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IDDict\n",
      "File \u001b[0;32m~/Desktop/Proggramering/Scalable Machine Learning/mlfs-book/.venv/lib/python3.12/site-packages/great_expectations/core/expectation_suite.py:10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgreat_expectations\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mge\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgreat_expectations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__ \u001b[38;5;28;01mas\u001b[39;00m ge_version\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluation_parameters\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     11\u001b[0m     _deduplicate_evaluation_parameter_dependencies,\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexpectation_configuration\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     14\u001b[0m     ExpectationConfiguration,\n\u001b[1;32m     15\u001b[0m     ExpectationConfigurationSchema,\n\u001b[1;32m     16\u001b[0m     expectationConfigurationSchema,\n\u001b[1;32m     17\u001b[0m )\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01musage_statistics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevents\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UsageStatsEvents\n",
      "File \u001b[0;32m~/Desktop/Proggramering/Scalable Machine Learning/mlfs-book/.venv/lib/python3.12/site-packages/great_expectations/core/evaluation_parameters.py:27\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyparsing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     11\u001b[0m     CaselessKeyword,\n\u001b[1;32m     12\u001b[0m     Combine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m     dictOf,\n\u001b[1;32m     24\u001b[0m )\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01murn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ge_urn\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m convert_to_json_serializable\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EvaluationParameterError\n\u001b[1;32m     30\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/Proggramering/Scalable Machine Learning/mlfs-book/.venv/lib/python3.12/site-packages/great_expectations/core/util.py:19\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_ipython\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgreat_expectations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m exceptions \u001b[38;5;28;01mas\u001b[39;00m ge_exceptions\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrun_identifier\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RunIdentifier\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InvalidExpectationConfigurationError\n",
      "File \u001b[0;32m~/Desktop/Proggramering/Scalable Machine Learning/mlfs-book/.venv/lib/python3.12/site-packages/great_expectations/exceptions/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/Proggramering/Scalable Machine Learning/mlfs-book/.venv/lib/python3.12/site-packages/great_expectations/exceptions/exceptions.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mabc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Iterable\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmarshmallow__shade\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ValidationError\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mGreatExpectationsError\u001b[39;00m(\u001b[38;5;167;01mException\u001b[39;00m):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, message) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/Proggramering/Scalable Machine Learning/mlfs-book/.venv/lib/python3.12/site-packages/great_expectations/marshmallow__shade/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdistutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LooseVersion\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmarshmallow__shade\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecorators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      4\u001b[0m     post_dump,\n\u001b[1;32m      5\u001b[0m     post_load,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     validates_schema,\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmarshmallow__shade\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ValidationError\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'distutils'"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "import hopsworks \n",
    "from openai import OpenAI\n",
    "from functions.llm_chain import (\n",
    "    load_model, \n",
    "    get_llm_chain, \n",
    "    generate_response, \n",
    "    generate_response_openai,\n",
    ")\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b062cc0",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üîÆ Connect to Hopsworks Feature Store </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6340e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you haven't set the env variable 'HOPSWORKS_API_KEY', then uncomment the next line and enter your API key\n",
    "# os.environ[\"HOPSWORKS_API_KEY\"] = \"\"\n",
    "\n",
    "project = hopsworks.login()\n",
    "fs = project.get_feature_store() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f2f191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get_or_create the 'air_quality_fv' feature view\n",
    "feature_view = fs.get_feature_view(\n",
    "    name='air_quality_fv',\n",
    "    version=1\n",
    ")\n",
    "\n",
    "# Initialize batch scoring\n",
    "feature_view.init_batch_scoring(1)\n",
    "\n",
    "weather_fg = fs.get_feature_group(\n",
    "    name='weather',\n",
    "    version=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8002765b",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">ü™ù Retrieve AirQuality Model from Model Registry</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02695f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the model registry\n",
    "mr = project.get_model_registry()\n",
    "\n",
    "# Retrieve the 'air_quality_xgboost_model' from the model registry\n",
    "retrieved_model = mr.get_model(\n",
    "    name=\"air_quality_xgboost_model\",\n",
    "    version=1,\n",
    ")\n",
    "\n",
    "# Download the saved model artifacts  to a local directory\n",
    "saved_model_dir = retrieved_model.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8930caa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the XGBoost regressor model and label encoder from the saved model directory\n",
    "# model_air_quality = joblib.load(saved_model_dir + \"/xgboost_regressor.pkl\")\n",
    "model_air_quality = XGBRegressor()\n",
    "\n",
    "model_air_quality.load_model(saved_model_dir + \"/model.json\")\n",
    "\n",
    "# Displaying the retrieved XGBoost regressor model\n",
    "model_air_quality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd30142d",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'>‚¨áÔ∏è LLM Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a911a86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# Load the LLM and its corresponding tokenizer.\n",
    "model_llm, tokenizer = load_model(model_id=\"imiraoui/OpenHermes-2.5-Mistral-7B-sharded\")\n",
    "\n",
    "duration = time.time() - start_time\n",
    "print(f\"The code execution took {duration} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e329285",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'>‚õìÔ∏è LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8caf5ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "# Create and configure a language model chain.\n",
    "llm_chain = get_llm_chain(\n",
    "    model_llm,\n",
    "    tokenizer,\n",
    ")\n",
    "\n",
    "duration = time.time() - start_time\n",
    "print(f\"The code execution took {duration} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2ded5c",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'>üß¨ Domain-specific Evaluation Harness\n",
    "\n",
    "**Systematic evaluations** that can run automatically in CI/CD pipelines are key to evaluating models/RAG. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58181b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION7 = \"Hi!\"\n",
    "\n",
    "response7 = generate_response(\n",
    "    QUESTION7,\n",
    "    feature_view,\n",
    "    weather_fg,\n",
    "    model_air_quality,\n",
    "    model_llm, \n",
    "    tokenizer,\n",
    "    llm_chain,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "print(response7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec32e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION = \"Who are you?\"\n",
    "\n",
    "response = generate_response(\n",
    "    QUESTION,\n",
    "    feature_view,\n",
    "    weather_fg,\n",
    "    model_air_quality,\n",
    "    model_llm, \n",
    "    tokenizer,\n",
    "    llm_chain,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d58ca1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION1 = \"What was the average air quality from 2024-01-10 till 2024-01-14?\"\n",
    "\n",
    "response1 = generate_response(\n",
    "    QUESTION1, \n",
    "    feature_view,\n",
    "    weather_fg,\n",
    "    model_air_quality,\n",
    "    model_llm, \n",
    "    tokenizer,\n",
    "    llm_chain,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "print(response1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d01dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION11 = \"When and what was the air quality like last week?\"\n",
    "\n",
    "response11 = generate_response(\n",
    "    QUESTION11, \n",
    "    feature_view,\n",
    "    weather_fg,\n",
    "    model_air_quality,\n",
    "    model_llm, \n",
    "    tokenizer,\n",
    "    llm_chain,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "print(response11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2d1a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION12 = \"When and what was the minimum air quality from 2024-01-10 till 2024-01-14?\"\n",
    "\n",
    "response12 = generate_response(\n",
    "    QUESTION12, \n",
    "    feature_view,\n",
    "    weather_fg,\n",
    "    model_air_quality,\n",
    "    model_llm, \n",
    "    tokenizer,\n",
    "    llm_chain,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "print(response12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659bad46",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION2a = \"What was the air quality like last week?\"\n",
    "\n",
    "response2 = generate_response(\n",
    "    QUESTION2a,\n",
    "    feature_view,\n",
    "    weather_fg,\n",
    "    model_air_quality,\n",
    "    model_llm, \n",
    "    tokenizer,\n",
    "    llm_chain,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "print(response2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35e6bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION2 = \"What was the air quality like yesterday?\"\n",
    "\n",
    "response2 = generate_response(\n",
    "    QUESTION2,\n",
    "    feature_view,\n",
    "    weather_fg,\n",
    "    model_air_quality,\n",
    "    model_llm, \n",
    "    tokenizer,\n",
    "    llm_chain,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "print(response2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed349483",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION3 = \"What will the air quality be like next Tuesday?\"\n",
    "\n",
    "response3 = generate_response(\n",
    "    QUESTION3, \n",
    "    feature_view,\n",
    "    weather_fg,\n",
    "    model_air_quality,\n",
    "    model_llm, \n",
    "    tokenizer,\n",
    "    llm_chain,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "print(response3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6825c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION4 = \"What will the air quality be like the day after tomorrow?\"\n",
    "\n",
    "response4 = generate_response(\n",
    "    QUESTION4, \n",
    "    feature_view,\n",
    "    weather_fg,\n",
    "    model_air_quality,\n",
    "    model_llm, \n",
    "    tokenizer,\n",
    "    llm_chain,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "print(response4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ac0709",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION5 = \"What will the air quality be like this Sunday?\"\n",
    "\n",
    "response5 = generate_response(\n",
    "    QUESTION5, \n",
    "    feature_view,\n",
    "    weather_fg,\n",
    "    model_air_quality,\n",
    "    model_llm, \n",
    "    tokenizer,\n",
    "    llm_chain,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "print(response5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee271416",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION7 = \"What will the air quality be like for the rest of the week?\"\n",
    "\n",
    "response7 = generate_response(\n",
    "    QUESTION7, \n",
    "    feature_view,\n",
    "    weather_fg,\n",
    "    model_air_quality,\n",
    "    model_llm, \n",
    "    tokenizer,\n",
    "    llm_chain,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "print(response7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aeeb4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION = \"Will the air quality be safe or not for the next week?\"\n",
    "\n",
    "response = generate_response(\n",
    "    QUESTION7, \n",
    "    feature_view,\n",
    "    weather_fg,\n",
    "    model_air_quality,\n",
    "    model_llm, \n",
    "    tokenizer,\n",
    "    llm_chain,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8b4e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION = \"Is tomorrow's air quality level dangerous?\"\n",
    "\n",
    "response = generate_response(\n",
    "    QUESTION, \n",
    "    feature_view,\n",
    "    weather_fg,\n",
    "    model_air_quality,\n",
    "    model_llm, \n",
    "    tokenizer,\n",
    "    llm_chain,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb26726",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION = \"Can you please explain different PM2_5 air quality levels?\"\n",
    "\n",
    "response = generate_response(\n",
    "    QUESTION, \n",
    "    feature_view,\n",
    "    weather_fg,\n",
    "    model_air_quality,\n",
    "    model_llm, \n",
    "    tokenizer,\n",
    "    llm_chain,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a463f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import locale\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fb77d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install openai --quiet\n",
    "# !pip install gradio==3.40.1 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4aebe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from functions.llm_chain import load_model, get_llm_chain, generate_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a442d20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the ASR pipeline\n",
    "transcriber = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-base.en\")\n",
    "\n",
    "def transcribe(audio):\n",
    "    sr, y = audio\n",
    "    y = y.astype(np.float32)\n",
    "    if y.ndim > 1 and y.shape[1] > 1:\n",
    "        y = np.mean(y, axis=1)\n",
    "    y /= np.max(np.abs(y))\n",
    "    return transcriber({\"sampling_rate\": sr, \"raw\": y})[\"text\"]\n",
    "\n",
    "def generate_query_response(user_query, method, openai_api_key=None):\n",
    "    if method == 'Hermes LLM':        \n",
    "        response = generate_response(\n",
    "            user_query,\n",
    "            feature_view,\n",
    "            weather_fg,\n",
    "            model_air_quality,\n",
    "            model_llm,\n",
    "            tokenizer,\n",
    "            llm_chain,\n",
    "            verbose=False,\n",
    "        )\n",
    "        return response\n",
    "    \n",
    "    elif method == 'OpenAI API' and openai_api_key:\n",
    "        client = OpenAI(\n",
    "            api_key=openai_api_key\n",
    "        )\n",
    "        \n",
    "        response = generate_response_openai(   \n",
    "            user_query,\n",
    "            feature_view,\n",
    "            weather_fg,\n",
    "            model_air_quality,\n",
    "            client=client,\n",
    "            verbose=True,\n",
    "        )\n",
    "        return response\n",
    "        \n",
    "    else:\n",
    "        return \"Invalid method or missing API key.\"\n",
    "\n",
    "def handle_input(text_input=None, audio_input=None, method='Hermes LLM', openai_api_key=\"\"):\n",
    "    if audio_input is not None:\n",
    "        user_query = transcribe(audio_input)\n",
    "    else:\n",
    "        user_query = text_input\n",
    "    \n",
    "    # Check if OpenAI API key is required but not provided\n",
    "    if method == 'OpenAI API' and not openai_api_key.strip():\n",
    "        return \"OpenAI API key is required for this method.\"\n",
    "\n",
    "    if user_query:\n",
    "        return generate_query_response(user_query, method, openai_api_key)\n",
    "    else:\n",
    "        return \"Please provide input either via text or voice.\"\n",
    "    \n",
    "\n",
    "# Setting up the Gradio Interface\n",
    "iface = gr.Interface(\n",
    "    fn=handle_input,\n",
    "    inputs=[\n",
    "        gr.Textbox(placeholder=\"Type here or use voice input...\"), \n",
    "        gr.Audio(), \n",
    "        gr.Radio([\"Hermes LLM\", \"OpenAI API\"], label=\"Choose the response generation method\"),\n",
    "        gr.Textbox(label=\"Enter your OpenAI API key (only if you selected OpenAI API):\", type=\"password\")  # Removed `optional=True`\n",
    "    ],\n",
    "    outputs=\"text\",\n",
    "    title=\"üå§Ô∏è AirQuality AI Assistant üí¨\",\n",
    "    description=\"Ask your questions about air quality or use your voice to interact. Select the response generation method and provide an OpenAI API key if necessary.\"\n",
    ")\n",
    "\n",
    "iface.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afa7c6a",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
